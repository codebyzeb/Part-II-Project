% Using template for a Computer Science Tripos Part II project dissertation
\documentclass[12pt,a4paper,twoside,openright]{report}
\usepackage[pdfborder={0 0 0}]{hyperref}    % turns references into hyperlinks
\usepackage[margin=25mm]{geometry}  % adjusts page layout
\usepackage{graphicx}  % allows inclusion of PDF, PNG and JPG images
\usepackage{verbatim}
\usepackage{docmute}   % only needed to allow inclusion of proposal.tex
\usepackage{natbib}
\usepackage{tikz}
\usepackage{wasysym}
\usepackage{amssymb}
\usepackage{textcomp}

\raggedbottom                           % try to avoid widows and orphans
\sloppy
\frenchspacing
\clubpenalty1000%
\widowpenalty1000%
\parindent 0pt
\parskip 6pt

\renewcommand{\baselinestretch}{1.1}    % adjust line spacing to make
                                        % more readable

\begin{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Title


\pagestyle{empty}

\rightline{\LARGE \textbf{Z\'ebulon Goriely}}

\vspace*{60mm}
\begin{center}
\Huge
\textbf{Simulating Language Learning and Evolution} \\[5mm]
Computer Science Tripos -- Part II \\[5mm]
Queens' College \\[5mm]
\today  % today's date
\end{center}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Proforma, table of contents and list of figures

\pagestyle{plain}

\chapter*{Proforma}

{\large
\begin{tabular}{ll}
Name:               & \bf Z\'ebulon Goriely                       \\
College:            & \bf Queens' College                     \\
Project Title:      & \bf Simulating Language Learning and Evolution \\
Examination:        & \bf Computer Science Tripos -- Part II, May 2020  \\
Word Count:         & \bf NULL\footnotemark[1]  \\
Project Originator: & Z\'ebulon Goriely                    \\
Supervisor:         & Prof. Paula Buttery and Dr. Andrew Caines                  \\ 
\end{tabular}
}
\footnotetext[1]{This word count was computed
by \texttt{detex diss.tex | tr -cd '0-9A-Za-z $\tt\backslash$n' | wc -w}
}
\stepcounter{footnote}


\section*{Original Aims of the Project}

Language has evolved and therefore probably gave an evolutionary advantage to the individuals that exhibited it. According to \citet{Cangelosi1998}, it is difficult to investigate the evolutionary origin of language and the selective pressures that may have originated language due to the limited evidence available. They propose using computer simulations of evolutionary scenarios to investigate this. In the paper referenced, they describe a simulated toy world where agents controlled by neural networks interact with an environment of mushrooms that are edible and poisonous. Exploring this simulation is the basis of my project.

\section*{Work Completed}

I implemented the mushroom-world simulation and explored three populations of feed-forward neural networks; one without language, one with an externally imposed language and one with an evolved language. To simulate evolution, I implemented a genetic algorithm to allow the fittest members of each generation to reproduce. The state of the simulation was saved at each generation in order plot the fitness of the three populations, plot the quality of the language produced and investigate behavioural tests. To conclude the project, I compared these findings with \citet{Cangelosi1998}.

\section*{Special Difficulties}

None.
 
\newpage
\section*{Declaration}

I, Z\'ebulon Goriely of Queens' College, being a candidate for Part II of the Computer
Science Tripos, hereby declare
that this dissertation and the work described in it are my own work,
unaided except as may be specified below, and that the dissertation
does not contain material that has already been used to any substantial
extent for a comparable purpose.

\bigskip
\leftline{Signed Z\'ebulon Goriely}

\medskip
\leftline{Date [date]}

\tableofcontents

\listoffigures

\newpage
\section*{Acknowledgements}

Paula et al.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Introduction

\pagestyle{headings}

\chapter{Introduction}

\section{Motivations}

Language has evolved and therefore probably gave an evolutionary advantage to the individuals that exhibited it. If we go back enough generations, we will find human ancestors that did not possess language. The field of language evolution is diverse and spans many scientific disciplines, from evolutionary biology and neurosciences to psycholinguistics and cultural anthropology. One of the main problems with studying the evolution of language is the relative abundance of theories compared to the limited empirical evidence. Language evolution is a once-occurring, long-term and complex system making it very difficult to study, but computer simulations may provide a means by which to examine the theories surrounding it.

Computer simulations are \emph{``theories of the empirical phenomena that are simulated"} \citep{cangelosi2012simulating}. Simulations encompass the hypotheses of the theory and produce empirical predictions that can then be evaluated against known phenomena \citet{cavalli1997genes}. Simulations can act as virtual laboratories where impossible experiments (such as language evolution) can be run, controlling parameters that could never be controlled in real life (such as evolutionary or environmental factors). Simulations can also act as quantitative verifiers for the internal validity of vague and ambiguous theories, requiring explicit definitions of key assumptions. Finally, simulations can be used as a tool for studying complex systems. These are composed of many interacting entities that produce global properties that can not be predicted even with complete knowledge of the system. Language is a complex system and it has been shown that the bottom-up approach of simulations can generate key insights \citep{langton1997artificial}.

\section{Prior Work}

Computer simulations have been applied to a variety of interesting questions in the field of language evolution. Seeking to investigate the emergence of syntactic universals, \citet{kirby2002emergence} presented the Iterated Learning Model (ILM), a means of simulating cultural transmission of language. They discuss the intersection of learning, cultural evolution and biological evolution as defining the emergence of language and use the ILM to explain the emergence of compositionality, irregularity and frequency properties of language.

To study the emergence of shared vowel systems, \citet{de1997generating} created a population-based language game model involving language games and genetic algorithms. He explores an apparent bias towards vowel systems that reflect the structure of human vowel systems, discussing how this is explained by the ``optimisation of acoustic distinctiveness'' from an information-theoretic perspective.

\citet{parisi2002unified}  discuss the use of a single unified simulation for the investigation of research questions surrounding the evolution of language. In particular, \citet{Cangelosi1998} introduces the ``toy mushroom world'' simulation for investigating how the evolution of categorisation abilities is linked to the evolution of communication signals for distinguishing these categories. A key question asked in this paper is how language can evolve when it has a purely informative function and so is  advantageous only to the receiver and not the producer. In further papers, Cangelosi explores how this simulation can be made more complex by introducing cultural transmission of language and finds that in compositional languages with a verb-noun structure, verbs have a larger positive effect on the performance of the species \citep{cangelosi2001evolution}.

\section{Project Overview}

In my project I re-implement the ``toy mushroom world'' simulation described in \citet{Cangelosi1998}. This involved the following contributions:

\begin{itemize}
	\item Implementing the environment populated with edible and poisonous `mushrooms'
	\item Implementing feed-forward neural networks from scratch to simulate the behaviour of the agents
	\item Implementing the genetic algorithm used to evolve the population over many generations
	\item Implementing three populations types categorised by their use of `language'
	\item Implementing a suite of data gathering tools, interactivity features and analysis methods to examine the behaviour of the simulation
\end{itemize}

In this chapter I have introduced why it can be useful to use computer simulations to help research the evolution of language. In the Chapter 2 I cover all of the preparations made for this project, including introducing the key concepts and discussing project management and software tools. In Chapter 3 I present my implementation of the simulation, breaking it down class by class. In the final two chapters I evaluate my project (Chapter 4), comparing my results to \citet{Cangelosi1998} before presenting my concluding remarks in Chapter 5. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Preparation

\chapter{Preparation}\label{chapter:preparation}

\emph{This chapter covers the background to my project in Sections \ref{section:world} to \ref{section:analysis}, then evaluates the requirements for the project in Section \ref{section:requirements}. I discuss the starting point of my project in Section \ref{section:starting} and the software engineering techniques used in Section \ref{section:software}.}

\section{Mushroom World}\label{section:world}

To explore how the introduction of language may affect a population's fitness, we need a simulated environment in which to test these changes. This ``mushroom world'' was described by \cite{Cangelosi1998}, inspired by the use of signals to communicate information about food location and quality present in may species.

The organisms will live in an environment populated by two different types of mushroom; edible and poisonous. The organisms will reproduce based on their ability to eat edible mushrooms and avoid the poisonous ones. They will need to learn to categorise the two mushrooms and respond accordingly by moving towards and eating the edible mushrooms and moving away from the poisonous mushrooms.

To ensure this categorisation is not trivial for the organisms, the mushrooms will have different properties. Edible mushrooms will resemble each other but will not be identical and likewise for poisonous mushrooms.

Each organism will live in an environment of $20 \times 20$ cells containing 20 randomly distributed mushrooms; 10 of which are poisonous and 10 of which are poisonous. They will be able to explore this world in 15 epochs of 50 simulation cycles each; in each new epoch the world is `reset', the position of the entity reset in a new environment with 20 new randomly distributed mushrooms. An example of this world can be seen in Figure \ref{fig:environment}.

\begin{figure}[h]
\centering
\begin{tikzpicture}
\draw[step=0.5cm,color=gray] (0,0) grid (10,10);
\node at (6.75,8.25){P};
\node at (5.75,2.25){P};
\node at (4.75,5.75){P};
\node at (6.75,4.25){P};
\node at (8.75,9.75){P};
\node at (4.75,7.25){P};
\node at (2.75,9.75){P};
\node at (0.25,8.25){P};
\node at (0.75,5.25){P};
\node at (7.75,5.75){P};
\node at (9.75,8.25){E};
\node at (2.75,9.25){E};
\node at (9.25,1.25){E};
\node at (8.75,1.75){E};
\node at (3.25,4.25){E};
\node at (2.75,6.25){E};
\node at (4.25,8.75){E};
\node at (6.75,7.25){E};
\node at (7.75,0.75){E};
\node at (6.25,0.75){E};
\node at (2.25,5.75){$\blacktriangle$};
\end{tikzpicture}
\caption{An organism ($\blacktriangle$) in the simulation environment with edible (E) and poisonous (P) mushrooms.}
\label{fig:environment}
\end{figure}

These constants are fairly arbitrarily chosen by Cangelosi and in later sections I will explore the effects of changing them, but for now I can intuitively explain some of these choices. The 15 epochs are used to average out the randomly generated positions of mushrooms so that it is really the behaviour of the organism that is being tested, not the random choice of environment. The 50 simulation cycles along with the specific dimensions of the environment ensures that the organism will likely be able to reach at least one edible mushroom but will unlikely be able to eat all edible mushrooms in time. This encourages productive strategies to search for edible mushrooms within the limited time available. Intuitively, this reflects the limited time that living organisms have to search for food in their lifetimes. A full list of constants can be seen in Table \ref{table:constants}.

\section{Entities}\label{section:entities}

In the simulation, organisms are represented by \emph{entities}. Entities can \emph{perceive} their surroundings and \emph{act} accordingly.

The perception is composed of three senses; the entity can sense the \emph{direction} of the nearest mushroom (a sort of `smelling' sense), can see the \emph{properties} of mushrooms it is adjacent to (a `visual' sense) and can receive \emph{signals} from other entities (a `auditory' sense). The adjacency restriction to the visual sense means that entities without any other signals must approach mushrooms in order to be able to categorise them.

The action is composed of two responses; the \emph{movement} of the entity and the \emph{signal} it produces. The movement is restricted to four options; moving one cell forwards, turning 90\textdegree~left, turning 90\textdegree~right and doing nothing. Instead of incorporating some `eat' action, a mushroom will be considered eaten when the entity moves into the cell that the mushroom occupies. The signal is used to communicate information to other entities when we explore adding language to the simulation.

The simulation should also incorporate evolution; some process by which the fittest entities of a species reproduce to pass on their behaviour to a new generation, with some degree of mutation. This will allow a population's average fitness to improve over many generations. From this abstract description of entities, I can consider how this system may be designed.

\subsection{Feed-Forward Neural Networks}\label{section:neural}

Inspired by the biological neural networks that constitute animal brains, \emph{artificial neural networks} are an appropriate choice for modelling the behaviour of these entities. Neural networks are composed of nodes (artificial neurons) which loosely model the neurons in a biological brain. Each node processes a signal by computing a non-linear function of the sum of the inputs. By organising these nodes into layers, signals can travel through from the input layer to the output layer. This is a \emph{feed-forward} neural network as there are no loops present to allow a signal to traverse a layer multiple times. A \emph{fully-connected} neural network feeds the output of every node in a layer into the input of every node in the next layer. 

Each node computes an input using a \emph{propagation function} as a weighted sum of the outputs of predecessor nodes, incorporating a \emph{bias} added to the result of the propagation. An \emph{activation function} can then be applied to produce the output of the node. As Cangelosi does not describe which activation function was used in his paper, I will explore the use of three common functions:

\begin{itemize}
	\item Identity: $f(x) = x$
	\item Sigmoid: $f(x) = \frac{1}{1+e^{-x}}$
	\item ReLU\footnote{ReLU stands for Rectified Linear Unit}:	$ f(x) = 
    \left\{
        \begin{array}{ll}
          0~\mathrm{for}~x \leq 0 \\
          x~\mathrm{for}~x > 0
        \end{array}
      \right.
      $
\end{itemize}

The entities can be represented by a fully-connected feed-forward neural network. The  \emph{perception} of the entity acts as the input of the neural network with the output treated as the \emph{action} chosen by the entity. To increase the computational abilities of the entity, I also include a layer of hidden nodes to allow for more complex decision making (INCLUDE REASON WHY HERE). This structure can be seen in Figure \ref{fig:neuralnet}. By altering the weights and biases used by the network, the entity will respond differently to the perceptual inputs, producing different behaviours. 

\begin{figure}[t]
  \centering
  \includegraphics[width=.6\linewidth]{figs/NeuralNets}
  \caption{Structure of a fully-connected ANN to control entity behaviour}
  \label{fig:neuralnet}
\end{figure}

\subsection{Alternative Structures}

- talk about linear regression

- talk about svms

- talk about more complex neural networks

\subsection{Genetic Algorithm}\label{section:genetic}

Similarly to how an artificial neural network is a natural implementation for simulating the behaviour of an entity, the \emph{genetic algorithm} is a natural implementation for simulating the population dynamics of a population of such entities. Just as artificial neural networks are inspired by animal brains, the genetic algorithm is inspired by the process of natural selection which is the very process that we want to simulate. 

Generally, a genetic algorithm takes a \emph{population} of candidate solutions to an optimisation problem and evolves the population towards a better solution. Each candidate has a set of properties, a \emph{genetic representation} which can be mutated and altered. The evolution starts from a population of randomly generated individuals and proceeds iteratively. For each \emph{generation}, the \emph{fitness} of each individual is calculated. The more fit individuals are selected and their genomes modified to form a new generation, used in the next iteration.

This maps neatly to our problem. The \emph{population} used by the algorithm is simply a group of entities. The \emph{genetic representation} of the entities is the set of weights and biases used by each neural network. The \emph{fitness} score, $F$ will be calculated according to the number of edible and poisonous mushrooms eaten by the entity during the simulation, $E$ and $P$ respectively:

\begin{equation}
\label{equation:fitness}
\mathrm{F} = 10 E- 11 P
\end{equation}

This rewards entities that eat edible mushrooms and punishes those that eat poisonous mushrooms. The difference in weight between these two scores gives a greater reward to the entities that eat more edible mushrooms than poisonous mushrooms as it punishes the greedy strategy of simply eating as many mushrooms as possible.

Finally, the reproduction occurs by selecting a percentage of the population with the highest fitness score and producing a small set of offspring for each of these individuals by randomly altering a percentage of the weights and biases in the neural network. In \cite{Cangelosi1998}, the top $20\%$ of entities are selected from a population of 100. Each of these entities produces five entities by randomly mutating $10\%$ of their weights and biases, producing a new generation of 100 entities. These introduce two new constants, as described in Table \ref{table:constants}.

\subsection{Population types}\label{section:populations}

To carry out the investigation of whether introducing language to a population increases its fitness, I will implement three different populations in the simulation. As described by \cite{Cangelosi1998}, these three populations differ in how the communication signals are used in the simulation environment. The three population types are:

\begin{itemize}
	\item No Language
	\item External Language
	\item Evolved Language
\end{itemize}

The population with no language acts as a baseline. The audio input to the neural network controlling the entity is set to a constant and the audio output is ignored. These entities cannot perceive the properties of the mushrooms unless they are adjacent; unlike the other populations they are not assisted by some linguistic signal.

The population with an externally provided language is slightly different. Here, I imagine that at the closest mushroom to the entity, another entity is present and can see the properties of the mushroom, generating an appropriate audio signal for the primary entity. The language is ``externally provided" because I will enforce that one signal is used for edible mushrooms and another is used for poisonous mushrooms without actually involving another entity in the simulation. 

The population with an evolved language is similar to the External Language population, but I will not enforce the use of particular signals. Instead, I will allow the population to derive its own signals. This will be done by pairing the primary entity with another randomly chosen entity at each simulation cycle. This second entity will be given same inputs as the primary entity as well as the properties of the closest mushroom, no matter the distance. This entity labels the mushroom for the primary entity. The audio output of this second entity will be used as the audio input to the primary entity; simulating a one-word utterance.

The differences between these populations can be seen in Figure \ref{fig:populations}.

\begin{figure}[t]
  \centering
  \includegraphics[width=.9\linewidth]{figs/populations}
  \caption{Differences in simulation structure for the three population types}
  \label{fig:populations}
\end{figure}

\begin{table*}[t]
\centering
 \begin{tabular}{ r | l | c}
 \bf{Constant} & \bf{Description} & \bf{Default Value} \\ [0.5ex] 
 \hline
dim\_x & The width of the simulation environment & 20 \\
dim\_y & The height of the simulation environment & 20 \\
num\_mushroom & The number of mushrooms placed in the environment & 20 \\
num\_epochs &  Number of epochs for each simulation & 15 \\ 
num\_cycles & Number of simulation cycles per epoch & 50 \\
num\_entities & Number of organisms in a population & 100 \\
num\_generations & Number of times a population will reproduce & 1000 \\
mutate\_percentage & The percentage of weights to mutate in reproduction & 10 \\
percentage\_keep & The percentage of organisms chosen to reproduce & 20 \\
\end{tabular}
\caption{A description of the constants and default values used for the simulation.}
\label{table:constants}
\end{table*}

\section{Simulation Analysis}\label{section:analysis}

\subsection{Generational Fitness}

As discussed in section \ref{section:genetic}, the fitness score for each entity describes its success in distinguishing between edible and poisonous mushrooms and correctly eating the former and avoiding the later. \cite{Cangelosi1998} plot the average fitness across 1000 generations to compare the three population types discussed in section \ref{section:populations}. This will be the primary way that I compare different runs of the simulation.

\subsection{Efficiency of Language}\label{section:efficiency}

\cite{Cangelosi1998} were also interested in the \emph{efficiency} of the language produced by these organisms. They gave three requirements for a population having an efficient language:

\begin{enumerate}
	\item Functionally distinct categories (e.g. mushroom type) are labelled with distinct signals
	\item A single signal tends to be used to label all instances within a category
	\item All the individuals in the population tend to use the same signal to label the same category
\end{enumerate}

These requirements were based on principles that \cite{Clark1995} argues govern a child's acquisition of a lexicon. To investigate the language produced by different populations, Cangelosi used a ``naming task''. In this controlled experiment, each entity in a population is exposed to the entire set of mushrooms (10 edible and 10 poisonous) in four locations (forward, left, backwards and right). This produces 80 signals per entity. The frequency distribution for the signals produced for edible and poisonous mushrooms by all entities can be plotted and this will be the second way I analyse the simulations.

\citet{Cangelosi1998} also described the calculation of a ``Quality Index'' (QI) to describe the efficiency of a language. The QI is calculated as follows:

\begin{equation}
\label{equation:dpoisonous}
d_{\mathrm{poisonous}} = \sum^{8}_{i = 1}{|x_i - x_e|}
\end{equation}
\begin{equation}
\label{equation:dedible}
d_{\mathrm{edible}} = \sum^{8}_{i = 1}{|y_i - y_e|}
\end{equation}
\begin{equation}
\label{equation:qi}
\mathrm{QI} = \sum^{8}_{i = 1} |x_i - y_i| + k \times \min (d_{\mathrm{poisonous}}, d_{\mathrm{edible}})
\end{equation}

$x_i$ and $y_i$ are the frequencies of signals used for poisonous and edible mushrooms respectively, as calculated from the ``naming task'' and $x_e$ and $y_e$ are the expected percentages in the case of a flat distribution. $k$ is a constant to weight the effect of the internal dispersion values $d_{\mathrm{poisonous}}$ and $d_{\mathrm{edible}}$ and is typically 1.

These dispersion values measure the variance of the distribution of signals used for the same category (edible or poisonous). This captures the use of synonyms, as these values are highest when only one signal is used for the category. 

The first part of the QI equation captures the principle of contrast (use of one word for each class of mushrooms) as it is highest when different signals are used for each category. By adding(?) this to the smaller of the two dispersion values, we get a score that captures the idea of an `efficient' language.

This will be the third way that I analyse the simulations; in particular I will examine the correlation between language efficiency and population fitness. In particular, it will be interesting to see if a correlation exists in the No Language population, despite not using any form of communication, as this would imply the parallel development of cognitive ability with linguistic ability.

LOOK INTO THIS EQUATION - A PLUS MAKES A LOT MORE SENSE

\section{Requirements Analysis}\label{section:requirements}

My project involves reimplementing the simulation described in sections \ref{section:world} - \ref{section:entities} and analysing this simulation in regards to the three metrics described in section \ref{section:analysis}. The requirements for this project can then be divided into two sections; implementing the simulation and constructing the means of analysis my implementation against the findings in \citet{Cangelosi1998}.

\subsection*{Implementing the Simulation}

\begin{enumerate}

\item Have a simulation environment with a world grid populated by poisonous and edible mushrooms as described in section \ref{section:world}. The simulation loop should be divided into regular `epochs'.

\item Have entities capable of navigating the environment, taking actions in each simulation cycle controlled by feedforward neural networks; with the structure described in section \ref{section:neural}.

\item Have a genetic algorithm that runs after all agents complete the simulation, as described in section \ref{section:genetic}.

\item Have three populations, one without language, one with an externally imposed language and one with an evolved language involving speaker-listening pairs, as described in section \ref{section:populations}.

\end{enumerate}

\subsection*{Analysis of the Simulation}

\begin{enumerate}

\item Have plots of the average fitness over the number of generations to compare between the three populations.

\item Have behavioural tests to investigate the behaviour of random individual organisms at specific generations.

\item Have plots the frequency distribution of the different signals produced by the individuals with the evolved language using a `naming task'.

\item Calculate the Quality Index (QI) of the language produced by the population without language and the population with an evolved language to investigate the genetic advantage of producing productive signals. 

\item Investigate the correlation between QI of the language and the fitness of the species to determine if change in the language or in the categorisation skill of the entities affects the linguistic ability.

\end{enumerate}

\section{Starting Point}\label{section:starting}

The implementation of the project is based on \citet{Cangelosi1998} which I familiarised myself with before beginning the project and in the early preporatory phases.

This project builds on concepts of simulations; I had a small amount of experience in programming simulations from an A-Level project in 2016. Before the project, I also read Simulating the Evolution of Language \citep{Cangelosi2002} to give me an overview of the techniques used in this field. 

This project builds on some of the content covered in the Artificial Intelligence course and the Formal Models of Language course form Part 1b. In particular, I had no experience with neural networks before beginning this project and all the code for the project was written from scratch and within the dates of the project.

\section{Software Engineering}\label{section:software}

\subsection{Languages and Libraries}

I chose Python for my project due to the ease of programming, my experience with it and the availability of good libraries for numerical analysis and plotting. To avoid code duplication, I made use of a few libraries:

\begin{enumerate}
 	\item To perform some scientific computing, I used SciPy\footnote{https://www.scipy.org/}.
	\item For the plotting of the analysis of the simulation, I used Matplotlib\footnote{https://matplotlib.org/}. 
	\item For producing unit tests, I used pytest\footnote{https://docs.pytest.org/}.
\end{enumerate}

\subsection{Project Management}

During implementation, I followed an agile development process. An initial project plan was formulated at the beginning of the project with a list of tasks to complete. These tasks were compiled into a Kanban board, with sections for Todo, In Progress, Testing/Documenting and Completed. My project plan divided the timeline of my project into a series of 2-3 week sprints, each with associated deadlines and milestones. At the beginning of each sprint I selected the tasks to complete in order to meet these deadlines and successfully pass each milestone, often completing additional tasks when work was completed early.

This agile process allowed me to ensure I was on track with my project. In fact, the success criteria proposed at the start of the project was met very early on in the timeline, allowing me to focus on refining the project and work on my extensions. 

\subsection{Version Control}

For version control, I used Git to track change with a remote repository on GitHub\footnote{https://github.com/}. This served as a backup, allowed me to revert to previous iterations of my code and allowed me to work on multiple computers. In particular, it allowed me to deploy my project to the University's High Performance Computing service for running the simulations, as discussed below. In addition, I also performed hardware backup to a hard drive twice a week.

\subsection{Development tools}

I made use of a number of tools to streamline my development process:

\begin{enumerate}
	\item I used Travis\footnote{https://travis-ci.org/} for continuous integration. With each commit, a script would automatically run all my unit tests and check my code for correct formatting.
	\item I used pylint\footnote{https://www.pylint.org/} to lint my code. This allowed me to ensure my code was readable and that I was complying with Google's python style guide\footnote{http://google.github.io/styleguide/pyguide.html}.
	\item I used yapf\footnote{https://github.com/google/yapf} to format my code consistently. I implemented a git hook to automatically format my code with each commit; the formatting was further checked by my Travis script.
\end{enumerate}

\subsection{Development environment}

I used Visual Studio Code\footnote{https://code.visualstudio.com/} as a development environment, due to the friendly interface and useful set of plugins that integrated nicely with git, pylint and pytest. 

To run my simulations, I used the University's High Performance Computing service. I created a set of Slurm scripts with a bash script that would allow me to schedule 30 simulations to run at once and independently. The results of these simulations were saved to files that I could copy to my local filesystem over SSH.

\subsection{Code License}

My source code is publicly available on GitHub with a README to explain how to use it. The project is licensed under the MIT license, for free modification and reuse while limiting my liability. It also preserves the copyright notice.

\section{Summary}\label{section:summary}

The evolution of language is an interesting problem that can be explored using simulations. In this project I will implement the ``mushroom world'' environment populated by entities controlled by neural networks with a genetic algorithm to model evolution. Three populations will be implemented; one without language, one with an external language and one with an evolved language. By comparing these populations in terms of fitness and language, I will be able to investigate the parallel development of the ability of the entities to categorise mushrooms and their ability to name them.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Implementation

\chapter{Implementation}

\begin{figure}[t]
  \centering
  \includegraphics[width=.9\linewidth]{figs/modules}
  \caption{Core modules for my project}
  \label{fig:modules}
\end{figure}

\begin{figure}[t]
  \centering
  \includegraphics[width=.9\linewidth]{figs/uml}
  \caption{UML Diagram for the Simulating Module}
  \label{fig:uml}
\end{figure}

\section{High-level Overview}

The implementation of my project is split into three modules as seen in Figure \ref{fig:modules}. The Simulating module contains all the code relevant to creating the simulation. This covers the ``Implementing the Simulation'' requirements for the project described in section \ref{section:requirements}. The Analysis module contains functions for plotting different graphs and carrying out the ``Analysis of the Simulation'' requirements for the project. Finally, the Experiments module contains a series of functions used for quickly running different variants of the simulation. 

Within the Simulating module, the classes correspond to the core concepts detailed in Chapter 2. A full UML diagram of this module (excluding tests) can be seen in Figure \ref{fig:uml}. The Entity class and subclasses correspond to the entities described in \ref{section:entities}. The Environment class corresponds to the ``mushroom world'' simulation environment described in Section \ref{section:world}. The Simulation class corresponds to the actual simulation, including the genetic algorithm (\ref{section:genetic}) and the different populations (\ref{section:populations}).

The Analysis module contains the code to analyse the simulation. This includes the plotting of generational fitness, language frequency and quality index as described in \ref{section:analysis}.

\section{Environment}

The Environment modules contains the Direction enumeration and the Environment class. These are used to represent the state of the mushroom world including the position of the mushrooms and the entity and the direction that the entity is facing. It contains methods for populating the world with mushrooms, managing the state of the world and querying the world.

\subsection{Mushrooms}\label{section:mushrooms}

Mushrooms are represented as 10-bit integers. Conceptually, each bit corresponds to a binary property of the mushroom. Poisonous mushrooms are represented as the bit-string 0b1111100000 with one randomly-chosen bit flipped. Similarly, edible mushrooms are represented by the bit-string 0b0000011111, again with one bit flipped. This means that edible and poisonous mushrooms may share two or zero bits in the same position.

To quickly generate mushrooms and test if mushrooms are edible or poisonous, I implemented functions \texttt{make\_edible()}, \texttt{make\_poisonous()}, \texttt{is\_edible()} and \texttt{is\_poisonous()}. For efficiency, these are implemented using bit-wise arithmetic.

\subsection{Representation of the World}

The 20x20 mushroom world is stored as a dictionary, mapping from (x,y) coordinates to mushroom values. Since there are at most 20 mushrooms at any point in the simulation, this dictionary holds at most 20 values at once. This data structure is chosen over an array representation as the world is sparse. Since the \texttt{closest\_mushroom()} function is called every simulation frame, we want this to be efficient and it is faster to iterate through 20 keys in a dictionary than through 400 cells in an array. 

Two runtime exceptions are implemented, \texttt{WorldFull} and \texttt{MushroomNotFound}. The methods that throw them are described below. Positions in the world are passed between methods as integer pairs (x, y). For the sake of clarity, the type \texttt{pos} will be used when such a pair is used.

The environment object has the following utility methods for manipulating and querying the status of the world:

\begin{itemize}
	\item \texttt{random\_position(): pos} --- Returns a random position within the dimensions of the world
	\item \texttt{random\_available\_position(): pos} --- Calls \texttt{random\_position()} iteratively until an unoccupied position is found. Throws a \texttt{WorldFull} exception if no cell is available
	\item \texttt{within\_bounds(pos): bool} --- Returns true if the position is within the world
	\item \texttt{adjacent(pos, pos): bool} --- Returns true if the two passed positions are adjacent
	\item \texttt{get\_angle(pos, pos, Direction): float} --- Returns the angle from one position to another, measured from 0 to 1 clockwise from the direction given
	\item \texttt{get\_cell(pos): int} --- Given a position, returns the mushroom at that position or 0 if the cell is empty
	\item \texttt{clear\_cell(pos): void} --- Removes a mushroom at the position specified and has no effect if the cell is empty
\end{itemize}

I then implemented the following methods for manipulating mushrooms in the world:

\begin{itemize}
	\item \texttt{place\_mushroom(int): void} --- Given a mushroom, places it in the world by calling \texttt{random\_available\_position()} and throws WorldFull if there is no space left
	\item \texttt{closest\_mushroom(int): pos} --- Returns the position of the closest mushroom in the world from a given position, using the manhattan distance
	\item \texttt{is\_mushroom(pos): bool} --- Returns true if there is a mushroom at the position specified
\end{itemize}

The \texttt{closest\_mushroom()} method loops through the position keys in the dictionary and for each of these calculates the Manhattan distance. The Manhattan distance is used because it is faster to calculate, it is always an overestimate (or equal to) the Euclidean distance and because the Entity can only move rectilinearly. 

{\renewcommand{\baselinestretch}{0.8}\small
\begin{verbatim}
def closest_mushroom(self, pos):
    """ Returns the position to the closest mushroom in the world.
    
    Args:
        pos (int, int): Position searching from.
    Raises:
        MushroomNotFound: No mushrooms found.

    """

    if len(self.world) == 0:
        raise MushroomNotFound("No Mushrooms in World")
        
    dist = self.dim_x + self.dim_y + 1
    mush_pos = (-1, -1)
    for (i, j) in self.world:
        # Use manhattan distance
        dist_to_mushroom = abs(pos[X] - i) + abs(pos[Y] - j)
        if dist_to_mushroom < dist:
            dist = dist_to_mushroom
            mush_pos = (i, j)

    return mush_pos
	
\end{verbatim}
}

\subsection{Entity Position}

The world also keeps track of the position and direction of the entity within it. This introduces a layer of abstraction between the Entity class and the Environment class; the Entity class is only concerned with the behaviour of the entity independently of the actual representation of its position and movement within the virtual world. The Simulation class acts as an interface between instances of these objects, discussed in section \ref{section:simulation}.

To represent the direction that the entity is facing, I implemented the enumeration \texttt{Direction} that stores the four values \texttt{NORTH, EAST, SOUTH, WEST} along with helper functions \texttt{right()} and \texttt{left()} to return the direction faced when turning right or turning left respectively.

I implemented the following methods for representing the entity in the world:

\begin{itemize}
	\item \texttt{place\_entity(): void} --- Gives the entity a random position in the world and throws \texttt{WorldFull} if there is no space for the entity
	\item \texttt{move\_entity(Action): void} --- Given an action, moves or rotates the entity accordingly
	\item \texttt{get\_entity\_position(): pos} --- Returns the position of the entity in the world
	\item \texttt{entity\_facing\_out(): bool} --- Returns true if the entity is at the edge of the world and facing out
	\item \texttt{get\_entity\_angle\_to\_position(pos): float} --- Returns the angle from the entity's position and uses the direction it is facing to return the angle to a given position by calling \texttt{get\_angle}.
\end{itemize}

When moving the entity, the \texttt{within\_bounds()} method is used to ensure that the entity does not move out of the world. The \texttt{entity\_facing\_out()} method is used for an optimisation discussed in section \ref{section:optimisations}.

\subsection{World Initialisation}

An Environment object is created by specifying the dimensions of the world and the number of edible and poisonous mushrooms expected. These are three of the `arbitrary' parameters described in Table \ref{table:constants}; by default the world is 20x20 and 10 of each mushroom type is placed randomly at the start of each epoch.

After creating a new object, the initialisation method calls the \texttt{reset()} method which places mushrooms in the world. This is separated from the initialisation because the world is reset at the start of each of the epochs that an entity experiences, removing any currently placed mushrooms.

\subsection{Testing}

Using pytest, I produced a series of unit tests to assert the behaviour of the Environment class. This was done early to ensure that any subsequent refactoring of the code would retain the correct behaviour of the program. This was ensured using Continuous Integration; after every Git commit a Travis Build would runt he test suite and report if any errors occurred.

\section{Entities}

The Entities module contains the Entity class and its two subclasses; ManualEntity and NeuralEntity. Separately, the Action module contains the Action enumeration to describe the possible actions taken by the entity. The full UML diagram can be seen in Figure \ref{fig:uml}.

\subsection{Action}

The entity can take four possible actions at each simulation step which are encapsulated in an enumeration; \texttt{FORWARDS} to move once cell forwards, \texttt{LEFT} to turn 90ยบ left, \texttt{RIGHT} to turn 90ยบ right and \texttt{NONE} to do nothing.

\subsection{Abstract Specification}

The Entity class acts as an empty parent class. As state, it has an \texttt{energy} value which is used to determine the fitness of the entity. The \texttt{eat(int)} method increases this value by 10 if passed an edible mushroom and decreases this value by 11 if passes a poisonous mushroom, according to equation \ref{equation:fitness}. 

The Entity class also defines the method \texttt{behaviour(float, int, float[]): Action, int[]}. This method describes the expected input-output behaviour of entities discussed in section \ref{section:entities}. When passed an angle, a mushroom and an input signal, this method returns an action and an output signal. The angle is passed as a float ranging from 0 to 1. The mushroom's properties are passed as a single integer, as described in section \ref{section:mushrooms}. The input and output communication signals are represented by three bits. The outputted action is an instance of the Action enumeration described above. These inputs and outputs are detailed in Table \ref{table:behaviour}. 

In the Entities class, the \texttt{behaviour} method always returns \texttt{Action.NOTHING} and the vocal signal \texttt{[0,0,0]}.

Note that the inputted and outputted audio signals have different datatypes. All audio signals are three-bit strings (encoding 8 possible signals) so outputted signals are always mapped to three bits. However, for the population without language, we input a constant audio signal \texttt{[0.5, 0.5, 0.5]}, requiring three floats. In the other two populations, the inputted audio signals are always comprised of three bits.

\begin{table*}[t]
\centering
 \begin{tabular}{ r | c | c | c}
 \bf{Signal} & \bf{Datatype} & \bf{Description} & \bf{Input / Output} \\ [0.5ex] 
 \hline
location & \texttt{float} & Angle to the nearest mushroom & Input \\
perception & \texttt{int} & Properties of the adjacent mushroom & Input \\
listening & \texttt{float[]} & A 3-bit audio signal (heard) & Input \\
vocal & \texttt{int[]} & A 3-bit audio signal (spoken) & Output \\
action & \texttt{Action} & The action taken by the Entity & Output \\
\end{tabular}
\caption{Inputs and Outputs of the \texttt{behaviour()} method}
\label{table:behaviour}
\end{table*}

\subsection{Rule-based Entity}

Before implementing the feed-forward neural networks to control the entities, I created a rule-based entity in the \texttt{ManualEntity} class which extends \texttt{Entity}. It overrides the \texttt{behaviour()} method and implements a simple algorithm to always rotate and move towards the nearest mushroom. On average, this strategy will produce a negative fitness score due to the poisonous mushroom penalty being higher than the edible mushroom reward. This behaviour is not analysed but was useful for the purpose of testing the simulation in the early stages of development due to the deterministic choices made.

\subsection{Neural Network Entity}

Once I had a functional simulation using rule-based entities, I implemented the feed-forward neural network used to control entities and allow their behaviour to evolve over many generations. In section \ref{section:neural} I gave the general structure for the fully-connected neural network I wanted to use to control the behaviour of the entities. Now that I have defined the datatypes for these inputs and outputs, I can produce a more concrete description of this neural network. 

The neural network has fourteen input units. The first unit is the float value \texttt{location} which describes the angle to the closest mushroom. The next ten units describe the bit-string representation of the mushroom the adjacent to the entity. Note that all these values are 0 if the entity is not adjacent to a mushroom (this is controlled by the simulation). The final three units are used for the inputted audio signal. Five hidden units are used, as in \citet{Cangelosi1998}. As discussed in Chapter 2, the paper does not specify the activation functions used in the neural network so I implemented three possible candidates:

\begin{itemize}
	\item Identity: $f(x) = x$
	\item Sigmoid: $f(x) = \frac{1}{1+e^{-x}}$
	\item ReLU: $ f(x) = 
    \left\{
        \begin{array}{ll}
          0~\mathrm{for}~x \leq 0 \\
          x~\mathrm{for}~x > 0
        \end{array}
      \right.
      $
\end{itemize}

There are five output units; two of which encode the action taken by the entity (as described above) and the remaining three encode the outputted communication signal (one of eight). The paper states that ``for all output units, continuous values are thresholded to either 0 or 1'' but is not clear how this thresholding takes place. I have decided to perform a sigmoid activation on the final layer (giving a float between 0 and 1) then rounding the result. The full neural network structure can be seen in Figure \ref{fig:fullneural}.

\begin{figure}[t]
  \centering
  \includegraphics[width=.9\linewidth]{figs/fullneural}
  \caption{Fully-connected ANN to control entity behaviour}
  \label{fig:fullneural}
\end{figure}

The \texttt{NeuralEntity} class introduces a few additional methods and some extra state. The \texttt{parameters} dictionary stores the weights and biases of the nodes in the neural network; mapping each layer number to two numpy matrices; the weights matrix corresponds to the weights associated with each edge in Figure \ref{fig:fullneural} and the biases matrix corresponding to the biases added to the weighted sum at each node. Creating a new \texttt{NeuralEntity} calls the \texttt{initialise\_parameters()} method to set the weights and biases to random values chosen from the rectangular distribution specified by [-1, 1].

The \texttt{forward\_propagation()} method carries out the forward propagation algorithm. At each layer, the weighted sum is calculated using the dot product of the weight matrix with the output of the previous layer, then the biases matrix is added before an activation function is performed to produce the outputs for that layer. For the final layer, a sigmoid activation is used as the activation function. Finally, the method rounds the outputs of the final layer and returns these as integers (0 or 1). This is the pseucodode for my implementation of forward propagation: 

\begin{verbatim}

1.  def forward_propagation(inputs):

2.    # Initialise the cache used to store activations and weighted sums
3.    activations <- []
4.    activations[0] = inputs
5.    final<- number of layers in the neural network

6.    # Calculate weighted sum (Z) and activation (A) at each layer
7.    for layer in (1, final_layer):
8.      Z <- dot(weights[layer], activations[layer-1]) + biases[layer]
9.      activations <- activation_function(Z)

10.   # Calculate activation on the final layer
11.   Z <- dot(weights[final], activations[final-1]) + biases[final]
12.   activations[final] = sigmoid(Z)

13.   # Round final layer to 0 or 1 and return
14.   outputs <- round(activations[final], 0, 1)
15.   return outputs

\end{verbatim}

\texttt{NeuralEntity} also overrides \texttt{behaviour()} in order to apply the neural network to the inputs. Given the inputs, it constructs a 14-element float vector as specified in Figure \ref{figure:fullneural}, in particular converting the integer mushroom to an array of bits. It then feeds this input vector to the \texttt{forward\_propagation()} method to get the output vector. The first two bits of this output vector are parsed as an instance of Action and the last three bits are returned as the output signal.

\subsection{Reproduction}

An important aspect of these neural entities is their ability to asexually reproduce to produce children. This is a vital part of the genetic algorithm and is implemented as a method \texttt{reproduce(int, float): Entity[]} in \texttt{NeuralEntity}.

The two parameters specify the number of children, $n$, to produce and the percentage of weights, $p$, in the neural network to mutate. When called, the entity starts by producing $n$ deep copies of itself. For each of these ``children'', it iterates through the weights and biases of their neural networks and uses $p$ to decide whether to mutate it. Mutation occurs by adding a random value in the rectangular distribution specified by [-1, 1] to the current value.

\subsection{Testing}

Similarly to with the Environment class, I used pytest to produced a series of unit tests to assert the behaviour of the Entity class and subclasses. Tests were created to assert the behaviour of every method implemented, such as ensuring that the pointers in the children entities generated by the \texttt{reproduce()} method are distinct from the pointers in the parent entity.

\section{Simulation}\label{section:simulation}

The Simulation module, seen in Figure \ref{fig:uml}, contains the Simulation class and the Language enumeration for implementing the simulation. The Simulation class is responsible for implementing the per-entity simulation (750 cycles in the Environment described above) and the population behaviour, including the genetic algorithm.

\subsection{Language}

The Language enumeration describes the differences in language between the populations as described in section \ref{section:populations}. \texttt{NONE} is used for no language, \texttt{EXTERNAL} for the external language and \texttt{EVOLVED} for the evolved language. This enumeration is used in the Simulation class and to distinguish between different behaviours.

\subsection{Initialising the Simulation}\label{section:simulation-initialise}

An instance of a Simulation object stores the parameters of the simulation and provides methods that run single-entity simulations and the genetic algorithm. The initialisation method sets the number of epochs (15 by default), the number of cycles per epoch (50 by default), the population size (100 by default) and the number of generations to run the simulation for (100 by default). These defaults are set fairly arbitrarily by \citet{Cangelosi1998} and were discussed section \ref{section:world}.

Further specified are two constants used by the genetic algorithm; the percentage of the population chosen to reproduce (20\% by default) and the percentage of weights to mutate (10\% by default). These were discussed in section \ref{section:genetic} and are listed with the other arbitrary constants in Table \ref{table:constants}.

\subsection{Single-Entity Simulation Run}\label{section:single-implementation}

The \texttt{run\_single()} method performs the main simulation for each entity. The pseudocode for this function is shown below. Taking a single entity as a parameter, it performs the relevant operations required to allow the entity to `live' in an instance of the Environment class for \texttt{num\_epochs} of \texttt{num\_cycles} time steps each. During this time, the entity's \texttt{behaviour()} method is passed the appropriate inputs according to its current position in the environment (lines 10 to 14). The outputs of the \texttt{behaviour()} method are interpreted accordingly, moving the entity in the environment (line 15). When the entity shares a cell with a mushroom, it eats it, changing its fitness score accordingly and the mushroom is removed from the environment (lines 17 to 19).

\begin{verbatim}

1. def run_single(entity):

2.   # Create a random environment
3.   env <- new Environment
  
4.   for epoch in num_epochs:

5.     # Reset mushroom positions and entity position between each epoch
6.     env.reset()
7.     env.place_entity()
  
8.     for cycle in num_cycles:
9.       # Gather inputs for the entity
10.      location <- angle from entity to closest mushroom
11.      perception <- bit string of mushroom if entity adjacent to it
12.      listening <- audio input signal according to language type
    
13.      # Get behaviour of the entity and move accordingly
14.      action <- entity.behaviour(location, perception, listening)
15.      env.move_entity(action)
      
16.      # Entity eats a mushroom if on top of one
17.      if env.entity_position is a mushroom:
18.        entity.eat(mushroom)
19.        env.remove(mushroom)

\end{verbatim}

Line 12 is implemented as three cases according to the \texttt{language\_type} property of the simulation. For no language, the signal is just set to \texttt{[0.5, 0.5, 0.5]}. For the external language, this signal is set to \texttt{[1, 0, 0]} if the closest mushroom is edible and \texttt{[0, 1, 0]} if it is poisonous.

For the evolved language, this step is slightly more complicated. The \texttt{run\_single()} method is also passed an array of the 99 other entities in the population and at each simulation step, one of these is randomly chosen to be the `partner entity' to name the closest mushroom for the primary entity. This other entity is given the same \texttt{location} parameter and a constant value of \texttt{[0.5, 0.5, 0.5]} as its \texttt{listening} signal but always receives the properties of the mushroom as its \texttt{perception} input, regardless of distance to the mushroom. The \texttt{action} output of the call to this partner entity's \texttt{behaviour()} call is ignored but the outputted signal is used as the inputted \texttt{listening} signal for our primary entity.

\subsection{Genetic Algorithm}

The \texttt{run\_population()} method implements the genetic algorithm used for this simulation. Given an initial population of entities, it runs the algorithm for \texttt{num\_generations} generations. The algorithm has three steps; performing the \texttt{run\_single()} method for each entity of the population, sorting the population to find the entities with the highest fitness and finally choosing a certain percentage of the fittest entities to reproduce to create the next population. The pseudocode for this process is shown below.

Lines 3-6 perform this first step by running the simulation for each entity in the current population. This simulation will update the fitness of each entity each time that an entity eats a mushroom. If the language being used is the evolved language, the \texttt{run\_single()} method is also passed a list of the other entities in the population to perform the appropriate naming as discussed in section \ref{section:single-implementation}.

Lines 7-9 perform the second step by simply sorting the list of entities according to the fitness achieved in each simulation. The top percentage of these entities is then selected for reproduction.

Lines 10-14 create the next population by calling the \texttt{reproduce()} method on each of the fittest parent entities identified. This method is passed the number of children to produce (the reciprocal of the percentage of parents selected) and the percentage of weights to adjust in the mutation process.

\begin{verbatim}

1.  def run_population(entities):

2.    for generation in num_generations:

3.      # Step 1: Run the simulation for each entity
4.      # Pass the remaining population for the evolved language
4.      for entity in entities:
5.         population <- entities - {entity}
6.         run_single(entity, population)
           
7.      # Step 2: Sort the entities by their fitness and select the best
8.      sort(entities, entity.fitness)
9.      best_entities <- top percentage_keep of entities

10.     # Step 3: Create a new population from the fittest entities
11.     children <- []
12.     for entity in best_entities:
13.       children += entity.reproduce(1/percentage_keep, mutate_percentage)
14.     population <- children

\end{verbatim}

Two key constants in this algorithm are \texttt{mutate\_percentage} and \texttt{percentage\_keep} which set the percentage of weights to mutate and the percentage of the population chosen for reproduction respectively. The setting of these constants was discussed in section \ref{section:simulation-initialise} above.

\subsection{Running the simulations using HPC}\label{section:running}

To run experiments, I acquired access to the University of Cambridge's High Performance Computing (HPC) facility. This gave me access to an environment where I could set up experiments and schedule runs of my program using SLURM. I created a series of bash scripts that would allow me to schedule a batch of jobs at once (for example 10 independent runs of the genetic algorithm for each language type).

Thus I could quickly make changes to my program, sync my code with my HPC environment using git then scheduling a series of jobs using SLURM. These jobs would then eventually be scheduled, would run on different nodes in the HPC and write data to files in my login space. This data could then be copied to my local computer using the \texttt{rsync} command. This work cycle allowed me to work quickly and effectively, all while avoiding having to use my own laptop for computationally demanding computations. 

\begin{table*}[t]
\centering
 \begin{tabular}{ c | c}
 \bf{Language Type} & \bf{Average Runtime} \\ [0.5ex] 
 \hline
NONE & 53:20 \\
EXTERNAL & 51:15\\
EVOLVED & 1:36:00 \\
\end{tabular}
\caption{Run times for the genetic algorithm according to language type, averaged across ten runs}
\label{table:runtimes}
\end{table*}

\subsection{Optimisations}\label{section:optimisations}

Although simulation speed is not the primary goal for this project (if it was I would not have used Python), it was still useful to consider some optimisations in order to increase the rate at which I could run experiments.

To find areas of the code to optimise, I analysed which method were called the most often using some basic analysis on the loop structures. If we consider a run of the genetic algorithm operating on a population of 100 entities for 1000 generations, we can already see that the \texttt{run\_single()} method is called 100000 times. If we consider that each single simulation is made up of 15 epochs of 50 cycles each then the perception-action loop described in section \ref{section:single-implementation} occurs 750 times for each of these 100000 calls. This gives us a total of 75 million repeats of any methods called in this perception-action loop.

The most expensive operation in this loop is the call to \texttt{behaviour()} which performs forward propagation, involving matrix multiplications. The other operations are less expensive, involving only getting and setting certain properties of the environment and entity. Furthermore, the \texttt{behaviour()} method is called twice for the population with the evolved language as it is used for the `naming' task to produce the input signal for the entity. By examining the difference in runtime between the No Language population and the Evolved Language population, we can estimate that calls to the the \texttt{behaviour()} method are responsible for approximately 80\% of the runtime for when the language type is \texttt{NONE} and 89\% when the language type is \texttt{EVOLVED}. This is calculated by comparing the average runtime of ten runs of the genetic algorithm for 1000 simulations for each language type, seen in Table \ref{table:runtimes}. My optimisations were thus focused on reducing the number of times this method was called and increasing the efficiency of the method for when it was called.

The first optimisation was to use numpy arrays to represent the neural network weights and to implement the matrix multiplications in the forward propagation algorithm. 

The first optimisation was made by taking advantage of the fact that the 100 calls to \texttt{run\_single()} at each generation can be made independently. Using the \texttt{multiprocessing} library for Python, I replaced the for loop with a \texttt{Pool} object which represents a pool of worker processes. The size of this pool is automatically set according to the number of processes available. Using the \texttt{Pool}, I call the \texttt{starmap} method to dynamically offload the 100 calls to \texttt{run\_single()} to these processes. This provides a significant speedup for our simulation depending on the number of processes available. 

Secondly, I optimised the texttt{run\_single()} method by reducing the number of simulation loops required in the early stages of the genetic algorithm. A simple optimisation could be made by noticing that the \texttt{behaviour()} method is entirely deterministic and that the environment that the entity interacts with is static. Thus, if the method returns the \texttt{NOTHING} action then the entity will not move, the inputs to \texttt{behaviour()} will not change and the method will continue to return \texttt{NOTHING} for the rest of the epoch. Thus, we can simply break from the current epoch and skip to the next one. Similarly, if the entity is at the edge of the world and attempts to move \texttt{FORWARD}, it will not move and will return the same response in the next cycle, so we can again skip the epoch. Note that we cannot skip the entire simulation because at the end of each epoch the position of the mushrooms and the entity are reset, which may change the inputs of the function.

More complicated optimisations of this form could be considered, such as detecting looping behaviours (spinning forever, moving backwards and forwards forever and so on). However, detecting these would increase the time and memory requirements for the program and would probably not yield a huge increase in performance for epochs of only 50 cycles.

\subsection{Interactivity}\label{section:interactivity}

In order to be able to watch the simulation and genetic algorithm occur live, I implemented interactive behaviour into the Simulation class. One of the parameters set by the \texttt{set\_io\_options()} method is the \texttt{interactive} property, False by default which allows this behaviour to occur.

An \texttt{initialise\_io} method is called at the start of the genetic algorithm to produce a live fitness over time graph for the genetic algorithm. In the primary loop for the genetic algorithm, an \texttt{io()} function is called to update this graph with the latest average fitness for the population. This allows the fitness of the population to be tracked live. An example of this is seen in Figure \ref{fig:interactive-fitness}.

The \texttt{io()} function also outputs other useful information and pauses the genetic algorithm to allow for interactivity. At each generation, the current generation, current list of fitness values and average energy for the current population is printed. The program then waits for user input before continuing. An inputted number will run the genetic algorithm for that many generations. Alternatively, by entering ``watch'' followed by a number, the program will allow the user to watch the behaviour of the entity indexed by the inputted number within the simulation. This is done by calling \texttt{run\_single()} again on the selected entity with an additional parameter, \texttt{viewer}, set to True.

The \texttt{run\_single()} method also has interactive behaviour when \texttt{viewer} is set to True. At each simulation step, the current world is displayed as a grid with emojis used to indicate the positions of edible and poisonous mushrooms. The position and direction of the entity is indicated using a triangle. This is done by converting the \texttt{Environment} object to a string; I had provided an implementation of the \texttt{\_\_str\_\_} method in the Environment class. Further information is also displayed, such as the current inputs and outputs to the entity at each step. This method is also paused for interactivity, the user presses ENTER to move to the next step or ESC to leave the viewer. This interactivity was crucial in early testing to locate complicated bugs and perform behavioural tests fo the system.

\subsection{Data Recording}

For the analysis of the simulation, I needed a few utility methods to collect data as it ran. The \texttt{initialise\_io} method is used to set a group of simulation parameters concerning how data is saved throughout the running of the simulation. These parameters are detailed in Table \ref{table:io-params}.

\begin{table*}[t]
\centering
 \begin{tabular}{ c | c | c}
 \bf{I/O Parameter} & \bf{Description} & \bf{Default Value} \\ [0.5ex] 
 \hline
interactive & Sets interactive behaviour on & False \\
record\_language & Whether to save the language & True \\
record\_language\_period & How often the language is saved & 1 \\
record\_entities & Whether to save the population of entities & True \\
record\_entities\_period & How often the population is saved & 1 \\
record\_fitness & Whether to save the average fitness & True \\
foldername & Where the data is saved in the local filesystem & ``folder'' \\
\end{tabular}
\caption{Run times for the genetic algorithm according to language type, averaged across ten runs}
\label{table:io-params}
\end{table*}

When the \texttt{io()} method is called, these parameters are used to control how often and whether data is recorded. The main information recorded is just the average fitness at each generation, used to produce the fitness graphs. This is done just by appending the current average fitness of the population to a file.

Language is recorded by performing a `naming task', as was described in section \ref{section:efficiency}. This is implemented by calling the \texttt{naming\_task()} method for each entity in the population, which calls \texttt{behaviour()} for 80 different possible inputs and recording the outputted signals. These signals are then written to a file by the \texttt{save\_language()} method which is called by \texttt{io()}.

The entities are saved by calling the \texttt{save\_entities()} method in \texttt{io()}. This simply uses the \texttt{pickle} library to save the list of entities to a binary file; easily loaded again with the \texttt{load\_entities()} method.

\section{Simulation Analysis}

The Analysis module seen in Figure \ref{fig:modules} contains the Plotting class and a variety of methods to analyse the simulation in the same manner as \citet{Cangelosi1998}. The Plotting class is used for displaying a live fitness graph, discussed above in section \ref{section:interactivity}.

\subsection{Fitness Graphs}

The fitness graphs were simply plotted by reading the average fitness values recorded from the simulation, plotting fitness over generation number. Typically I ran 10 simulations for each language type at once, so another method plotted the average of ten of these fitness graphs.

\subsection{Language Frequency Distributions}

Similarly to the fitness graphs, I implemented a method for plotting the frequency distribution of the language. It plots a bar graph with frequency on the y-axis and each of the eight possible signals on the x-axis. The signals used for edible and poisonous mushrooms were separated by colour and the method allowed for the frequency distribution of several different generations to be compared by stacking them above each other; this allows for observing the convergence of signals to a productive language.

\subsection{QI Score}

I then implemented methods for calculating the QI score of the language produced by the population as given in equation \ref{equation:qi} in section \ref{section:efficiency}. \citet{Cangelosi1998} used this equation to correlate language efficiency with fitness and found that even in a population that did not use language, there was a high correlation between fitness and QI score over 1000 generations. Upon initial analysis of my simulation however, I only achieved low and negative correlation scores between fitness and the QI score defined by equation \ref{equation:qi}. 

PUT INITIAL RESULTS HERE

Interpreting this equation further we can see that their equation does not match their definition of a productive language. The first half of the equation, $\sum^{8}_{i = 1} |x_i - y_i|$ has a maximum value of 2 if no signal is used for both edible and poisonous mushrooms, so is large if the language is efficient. The second half of this equation, $\min (d_{\mathrm{poisonous}}$ has a maximum value of 1.75 if only one signal is used for each mushroom type, thus is also large if the language is efficient. 

This means that if the QI equation is meant to capture language efficiency, then these two values should be \emph{added} instead of subtracted. I thus implemented the equation as the following:

\begin{equation}
\label{equation:qibetter}
\mathrm{QI} = \sum^{8}_{i = 1} |x_i - y_i| + k \times \min (d_{\mathrm{poisonous}}, d_{\mathrm{edible}})
\end{equation}

This gave far better correlations, as discussed in the next chapter.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Evaluation

\chapter{Evaluation}

\emph{Show graphs, run by run etc.}

\emph{Variance is interesting to discuss}

\emph{Could also be interesting to query what happens in an elbow in the graph - visual and a bit subjective. Three categories - those that do not take off, those that suddenly take off and those that gradually take off.}

\emph{Variance in each run, consequences of initialisation/activation, bigger questions about how reliable neural networks are, whether they are a good model for language evolution. }

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Conclusion

\chapter{Conclusion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% the bibliography
\addcontentsline{toc}{chapter}{Bibliography}
\bibliography{refs}
\bibliographystyle{apalike}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% the appendices
\appendix

\chapter{Project Proposal}

\input{proposal}

\end{document}
